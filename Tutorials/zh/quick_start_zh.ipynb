{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 0：准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，在环境中安装 FlagEmbedding。\n",
    "\n",
    "`pip install -U FlagEmbedding`\n",
    "\n",
    "以下是一个非常小的语料库，仅包含 10 个句子，我们将用它作为数据集。\n",
    "\n",
    "每个句子都是对某一领域著名人物的简明描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"迈克尔·杰克逊是一位传奇的流行音乐偶像，以其破纪录的音乐和舞蹈创新而闻名。\",\n",
    "    \"李飞飞是斯坦福大学教授，通过ImageNet项目彻底改变了计算机视觉领域。\",\n",
    "    \"布拉德·皮特是一位多才多艺的演员兼制片人，因在《搏击俱乐部》和《好莱坞往事》等影片中的角色而闻名。\",\n",
    "    \"杰弗里·辛顿是人工智能领域的奠基性人物，因其在深度学习方面的贡献而荣获图灵奖。\",\n",
    "    \"埃米纳姆是一位著名的说唱歌手，是有史以来销量最高的音乐艺术家之一。\",\n",
    "    \"泰勒·斯威夫特是一位格莱美获奖的创作歌手，以其叙事性强的音乐而著称。\",\n",
    "    \"萨姆·奥尔特曼担任OpenAI的首席执行官，主导了GPT系列的惊人成果，并致力于推动安全且有益的人工智能发展。\",\n",
    "    \"摩根·弗里曼是一位备受赞誉的演员，以其独特嗓音和多样化的角色而闻名。\",\n",
    "    \"吴恩达通过在Coursera和斯坦福大学开设公开课，将人工智能知识传播至全球。\",\n",
    "    \"小罗伯特·唐尼是一位标志性演员，最广为人知的角色是在漫威电影宇宙中饰演钢铁侠。\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们想知道这些人中谁可能是神经网络领域的专家，以及他/她是谁。\n",
    "\n",
    "因此，我们生成了以下查询："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"谁可能是神经网络领域的专家？\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 1：文本 → 嵌入向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们使用 [BGE 嵌入模型](https://huggingface.co/BAAI/bge-base-zh-v1.5) 为语料库中的句子生成嵌入向量。\n",
    "\n",
    "注：国内用户手动下载。\n",
    "\n",
    "```powershell\n",
    "# 激活虚拟环境\n",
    ".\\.venv\\Scripts\\Activate.ps1\n",
    "\n",
    "# 设置镜像\n",
    "$env:HF_ENDPOINT = \"https://hf-mirror.com\"\n",
    "\n",
    "# 使用 huggingface-cli 下载（确保已安装 huggingface_hub >= 0.14）\n",
    "huggingface-cli download --resume-download BAAI/bge-base-zh-v1.5 --local-dir ./.models/bge-base-zh-v1.5 --local-dir-use-symlinks False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: e:\\git\\FlagEmbedding-cn\\.models\\bge-base-zh-v1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from FlagEmbedding import FlagModel\n",
    "try:\n",
    "    # 脚本环境\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    # Notebook / 交互式环境\n",
    "    current_dir = os.getcwd()  # 使用当前工作目录\n",
    "\n",
    "# 推断项目根目录：上两级（zh -> Tutorials -> FlagEmbedding-cn）\n",
    "project_root = os.path.dirname(os.path.dirname(current_dir))\n",
    "\n",
    "# 拼接模型路径\n",
    "model_path = os.path.join(project_root, \".models\", \"bge-base-zh-v1.5\")\n",
    "\n",
    "print(\"Loading model from:\", model_path)\n",
    "# 获取 BGE 嵌入模型\n",
    "model = FlagModel(model_path,\n",
    "                  query_instruction_for_retrieval=\"为检索相关段落而对这个句子进行表示：\",\n",
    "                  use_fp16=True)\n",
    "\n",
    "# 获取查询和语料库的嵌入\n",
    "corpus_embeddings = model.encode(corpus)\n",
    "query_embedding = model.encode(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个句子的嵌入是一个长度为 768 的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询嵌入的形状： (768,)\n",
      "语料库嵌入的形状： (10, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"查询嵌入的形状：\", query_embedding.shape)\n",
    "print(\"语料库嵌入的形状：\", corpus_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行以下打印语句，查看查询嵌入向量的前 10 个元素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02136574 -0.02101879  0.00016666  0.01245924  0.04682833  0.03393672\n",
      "  0.0190743  -0.04130525 -0.00147657  0.04505555]\n"
     ]
    }
   ],
   "source": [
    "print(query_embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 2：计算相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们已经获得了查询和语料库的嵌入向量。下一步是计算查询与语料库中每个句子之间的相似度。这里我们使用点积（内积）作为相似度度量指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27556407 0.51574427 0.3341428  0.54028046 0.3247512  0.33678967\n",
      " 0.4857601  0.32122058 0.43284306 0.34145787]\n"
     ]
    }
   ],
   "source": [
    "sim_scores = query_embedding @ corpus_embeddings.T\n",
    "print(sim_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果是一个得分列表，表示查询与以下各项的相似度：[句子0, 句子1, 句子2, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 3：排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在获得查询与语料库中每个句子的相似度得分后，我们可以将这些得分从大到小进行排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 6, 8, 9, 5, 2, 4, 7, 0]\n"
     ]
    }
   ],
   "source": [
    "# 获取按排序顺序排列的索引\n",
    "sorted_indices = sorted(range(len(sim_scores)), key=lambda k: sim_scores[k], reverse=True)\n",
    "print(sorted_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据排序结果，索引为 3 的句子是对我们查询 “谁可能是神经网络领域的专家？” 的最佳回答。\n",
    "\n",
    "而这位专家正是 杰弗里·辛顿！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "杰弗里·辛顿是人工智能领域的奠基性人物，因其在深度学习方面的贡献而荣获图灵奖。\n"
     ]
    }
   ],
   "source": [
    "print(corpus[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据索引的排序顺序，我们可以打印出这个小型检索系统得到的人物排名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分 0.540: \"杰弗里·辛顿是人工智能领域的奠基性人物，因其在深度学习方面的贡献而荣获图灵奖。\"\n",
      "得分 0.516: \"李飞飞是斯坦福大学教授，通过ImageNet项目彻底改变了计算机视觉领域。\"\n",
      "得分 0.486: \"萨姆·奥尔特曼担任OpenAI的首席执行官，主导了GPT系列的惊人成果，并致力于推动安全且有益的人工智能发展。\"\n",
      "得分 0.433: \"吴恩达通过在Coursera和斯坦福大学开设公开课，将人工智能知识传播至全球。\"\n",
      "得分 0.341: \"小罗伯特·唐尼是一位标志性演员，最广为人知的角色是在漫威电影宇宙中饰演钢铁侠。\"\n",
      "得分 0.337: \"泰勒·斯威夫特是一位格莱美获奖的创作歌手，以其叙事性强的音乐而著称。\"\n",
      "得分 0.334: \"布拉德·皮特是一位多才多艺的演员兼制片人，因在《搏击俱乐部》和《好莱坞往事》等影片中的角色而闻名。\"\n",
      "得分 0.325: \"埃米纳姆是一位著名的说唱歌手，是有史以来销量最高的音乐艺术家之一。\"\n",
      "得分 0.321: \"摩根·弗里曼是一位备受赞誉的演员，以其独特嗓音和多样化的角色而闻名。\"\n",
      "得分 0.276: \"迈克尔·杰克逊是一位传奇的流行音乐偶像，以其破纪录的音乐和舞蹈创新而闻名。\"\n"
     ]
    }
   ],
   "source": [
    "# 依次按降序打印得分及对应的句子\n",
    "\n",
    "for i in sorted_indices:\n",
    "    print(f\"得分 {sim_scores[i]:.3f}: \\\"{corpus[i]}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从排名结果来看，不出所料，查询与杰弗里·辛顿（Geoffrey Hinton）和李飞飞（Fei-Fei Li）描述之间的相似度得分远高于其他人，其次是吴恩达（Andrew Ng）和萨姆·奥尔特曼（Sam Altman）。\n",
    "\n",
    "尽管查询中的关键词短语 “神经网络” 并未出现在任何描述中，但 BGE 嵌入模型依然足够强大，能够准确捕捉查询与语料库文本之间的语义含义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤 4：评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经看到嵌入模型在“神经网络”查询上的表现相当不错。那么它在更一般情况下的整体质量如何呢？\n",
    "\n",
    "让我们构建一个非常小的查询数据集，并为每个查询提供对应的标准答案（ground truth）。注意，这些标准答案是语料库中句子的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"谁可能是神经网络领域的专家？\",\n",
    "    \"谁可能获得过格莱美奖？\",\n",
    "    \"获得过奥斯卡奖\",\n",
    "    \"最著名的女歌手之一。\",\n",
    "    \"AlexNet 的发明者\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [\n",
    "    [1, 3],\n",
    "    [0, 4, 5],\n",
    "    [2, 7, 9],\n",
    "    [5],\n",
    "    [3],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们重复上述步骤，为每个查询获取预测的排序结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 1, 6, 8, 9, 5, 2, 4, 7, 0],\n",
       " [5, 3, 2, 7, 9, 4, 0, 1, 6, 8],\n",
       " [5, 2, 3, 7, 9, 1, 4, 0, 8, 6],\n",
       " [4, 5, 0, 7, 3, 2, 9, 8, 6, 1],\n",
       " [1, 3, 6, 8, 0, 4, 5, 9, 2, 7]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 BGE 模型为所有查询生成嵌入向量。\n",
    "queries_embedding = model.encode(queries)\n",
    "# 计算相似度得分\n",
    "scores = queries_embedding @ corpus_embeddings.T\n",
    "# 获取最终的排名\n",
    "rankings = [sorted(range(len(sim_scores)), key=lambda k: sim_scores[k], reverse=True) for sim_scores in scores]\n",
    "rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均倒数排名（[MRR](https://en.wikipedia.org/wiki/Mean_reciprocal_rank)）是信息检索中广泛使用的一种评估指标。在这里，我们使用它来粗略了解我们系统的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MRR(preds, labels, cutoffs):\n",
    "    mrr = [0 for _ in range(len(cutoffs))]\n",
    "    for pred, label in zip(preds, labels):\n",
    "        for i, c in enumerate(cutoffs):\n",
    "            for j, index in enumerate(pred):\n",
    "                if j < c and index in label:\n",
    "                    mrr[i] += 1/(j+1)\n",
    "                    break\n",
    "    mrr = [k/len(preds) for k in mrr]\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们选择将 1 和 5 作为截断点（cutoffs），分别得到了 0.4 和 0.7 的结果。这表明，在这个小型数据集上，我们的嵌入模型表现良好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@1: 0.4\n",
      "MRR@5: 0.7\n"
     ]
    }
   ],
   "source": [
    "cutoffs = [1, 5]\n",
    "mrrs = MRR(rankings, ground_truth, cutoffs)\n",
    "for i, c in enumerate(cutoffs):\n",
    "    print(f\"MRR@{c}: {mrrs[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
